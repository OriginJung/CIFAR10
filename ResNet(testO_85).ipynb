{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_RZwj_ZCRLhv"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim, cuda\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU settings\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device, \"\\n\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqLYe76vRZT2",
        "outputId": "ebb2ef75-9016-4365-aa6e-33171d19973f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings\n",
        "batch_size = 256 \n",
        "\n",
        "# CIFER10 Dataset\n",
        "# train_dataset nomalize\n",
        "train_dataset = datasets.CIFAR10(root='./data',\n",
        "                              train=True,\n",
        "                              transform=transforms.ToTensor(),\n",
        "                              download=True)\n",
        "\n",
        "print(\"data shape:\", train_dataset.data.shape)\n",
        "\n",
        "train_mean = train_dataset.data.mean(axis=(0, 1, 2))\n",
        "train_std = train_dataset.data.std(axis=(0, 1, 2))\n",
        "\n",
        "train_mean = train_mean / 255\n",
        "train_std = train_std / 255\n",
        "\n",
        "print(\"train_mean:\", train_mean)\n",
        "print(\"train_std:\", train_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7twL70G9RZWd",
        "outputId": "08326d84-8f58-4d13-a2b9-acae981f12f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 35949490.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "data shape: (50000, 32, 32, 3)\n",
            "train_mean: [0.49139968 0.48215841 0.44653091]\n",
            "train_std: [0.24703223 0.24348513 0.26158784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_dataset nomalize\n",
        "test_dataset = datasets.CIFAR10(root='./data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "print(\"data shape:\", test_dataset.data.shape)\n",
        "\n",
        "test_mean = test_dataset.data.mean(axis=(0, 1, 2))\n",
        "test_std = test_dataset.data.std(axis=(0, 1, 2))\n",
        "\n",
        "test_mean = test_mean / 255\n",
        "test_std = test_std / 255\n",
        "\n",
        "print(\"test_mean:\", test_mean)\n",
        "print(\"test_std:\", test_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHBvc3BbRZZB",
        "outputId": "13778ced-eace-4e57-fac0-0969ed42049b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (10000, 32, 32, 3)\n",
            "test_mean: [0.49421428 0.48513139 0.45040909]\n",
            "test_std: [0.24665252 0.24289226 0.26159238]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(test_mean, test_std)\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data',\n",
        "                              train=True,\n",
        "                              transform=train_transform,\n",
        "                              download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data/',\n",
        "                              train=False,\n",
        "                              transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLbUFOFJRZbd",
        "outputId": "7066ff92-05ba-4ec2-e3e3-76395be72728"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1) # /stride\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True) # inplace 옵션의 역할이 무엇인가?\n",
        "        self.conv2 =  nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1) # \n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.im = lambda x: x # identity mapping\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual=self.im(x)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(residual)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "c0HBzQn7RZeK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet_CIFAR10(nn.Module):\n",
        "    def __init__(self, block, layers, zero_init_residual=False):\n",
        "        super(ResNet_CIFAR10, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        # 3, 32, 32\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) # bias?????????????????????\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True) # inplace???????????????\n",
        "        self.mp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # 64, 32, 32\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        # 64, 32, 32\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        # 128, 16, 16\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        # 256, 8, 8\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        # 512, 4, 4\n",
        "        self.ap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # 512, 1, 1\n",
        "        self.fc = nn.Linear(512, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "    \n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1: \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels, 1, stride),\n",
        "                nn.BatchNorm2d(out_channels),#??????????\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        \n",
        "        self.in_channels = out_channels\n",
        "        \n",
        "        for _ in range(1, blocks): \n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        # x = self.mp(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.ap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = F.log_softmax(x)\n",
        "        return x\n",
        "\n",
        "model = ResNet_CIFAR10(ResidualBlock, [2, 2, 2, 2]) # ResNet20\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) "
      ],
      "metadata": {
        "id": "adZLxkrNRZgp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # data, target = Variable(data), Variable(target)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "sftKl5H6RZja"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # data, target = Variable(data, volatile=True), Variable(target)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('Test set({}): Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        epoch, test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    return 100. * correct / len(test_loader.dataset)"
      ],
      "metadata": {
        "id": "q3RU42y1RZl6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=[]\n",
        "for epoch in range(1, 100):\n",
        "    train(epoch)\n",
        "    accuracy.append(test(epoch))\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot([i for i in range(len(accuracy))], accuracy)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Result')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u9EXylWMRZoB",
        "outputId": "4d12ccc8-04a9-41a2-9805-5f126b0d5522"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-a9ca00db8409>:73: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.479803\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.838874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set(1): Average loss: 1.7188, Accuracy: 3616/10000 (36%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.620825\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.585295\n",
            "Test set(2): Average loss: 1.4664, Accuracy: 4471/10000 (45%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.442098\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.403310\n",
            "Test set(3): Average loss: 1.3374, Accuracy: 5124/10000 (51%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.229727\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.227149\n",
            "Test set(4): Average loss: 1.2444, Accuracy: 5480/10000 (55%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.246244\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.098435\n",
            "Test set(5): Average loss: 1.2783, Accuracy: 5505/10000 (55%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.135929\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.144717\n",
            "Test set(6): Average loss: 1.1388, Accuracy: 5967/10000 (60%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.034418\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.099255\n",
            "Test set(7): Average loss: 1.1153, Accuracy: 6071/10000 (61%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.993387\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.145879\n",
            "Test set(8): Average loss: 1.1044, Accuracy: 6260/10000 (63%)\n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.989389\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.965882\n",
            "Test set(9): Average loss: 1.1127, Accuracy: 6220/10000 (62%)\n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.053761\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.889768\n",
            "Test set(10): Average loss: 0.9821, Accuracy: 6575/10000 (66%)\n",
            "\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.886108\n",
            "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.834948\n",
            "Test set(11): Average loss: 0.9721, Accuracy: 6636/10000 (66%)\n",
            "\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.855668\n",
            "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.794523\n",
            "Test set(12): Average loss: 0.9391, Accuracy: 6755/10000 (68%)\n",
            "\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.841977\n",
            "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.657473\n",
            "Test set(13): Average loss: 0.8921, Accuracy: 6991/10000 (70%)\n",
            "\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.798998\n",
            "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.698296\n",
            "Test set(14): Average loss: 0.9247, Accuracy: 6887/10000 (69%)\n",
            "\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.663464\n",
            "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.718361\n",
            "Test set(15): Average loss: 0.8740, Accuracy: 7042/10000 (70%)\n",
            "\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.620086\n",
            "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.659332\n",
            "Test set(16): Average loss: 0.8755, Accuracy: 7099/10000 (71%)\n",
            "\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.678666\n",
            "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.635064\n",
            "Test set(17): Average loss: 0.8717, Accuracy: 7125/10000 (71%)\n",
            "\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.546309\n",
            "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.548799\n",
            "Test set(18): Average loss: 0.8143, Accuracy: 7287/10000 (73%)\n",
            "\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.698658\n",
            "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.492038\n",
            "Test set(19): Average loss: 0.7902, Accuracy: 7413/10000 (74%)\n",
            "\n",
            "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.512416\n",
            "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.526023\n",
            "Test set(20): Average loss: 0.7655, Accuracy: 7436/10000 (74%)\n",
            "\n",
            "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.517888\n",
            "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.607889\n",
            "Test set(21): Average loss: 0.8544, Accuracy: 7310/10000 (73%)\n",
            "\n",
            "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.492084\n",
            "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.533739\n",
            "Test set(22): Average loss: 0.8045, Accuracy: 7411/10000 (74%)\n",
            "\n",
            "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.582657\n",
            "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.524571\n",
            "Test set(23): Average loss: 0.7157, Accuracy: 7692/10000 (77%)\n",
            "\n",
            "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.534501\n",
            "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.506459\n",
            "Test set(24): Average loss: 0.7135, Accuracy: 7674/10000 (77%)\n",
            "\n",
            "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.589110\n",
            "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.525119\n",
            "Test set(25): Average loss: 0.7782, Accuracy: 7630/10000 (76%)\n",
            "\n",
            "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.438835\n",
            "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.427667\n",
            "Test set(26): Average loss: 0.7236, Accuracy: 7690/10000 (77%)\n",
            "\n",
            "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.429157\n",
            "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.414000\n",
            "Test set(27): Average loss: 0.6557, Accuracy: 7906/10000 (79%)\n",
            "\n",
            "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.452890\n",
            "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.502114\n",
            "Test set(28): Average loss: 0.6420, Accuracy: 7955/10000 (80%)\n",
            "\n",
            "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.431212\n",
            "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.415776\n",
            "Test set(29): Average loss: 0.6647, Accuracy: 7920/10000 (79%)\n",
            "\n",
            "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.366265\n",
            "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.340894\n",
            "Test set(30): Average loss: 0.8570, Accuracy: 7375/10000 (74%)\n",
            "\n",
            "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.331323\n",
            "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.342935\n",
            "Test set(31): Average loss: 0.6350, Accuracy: 7967/10000 (80%)\n",
            "\n",
            "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.339502\n",
            "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.290977\n",
            "Test set(32): Average loss: 0.6987, Accuracy: 7848/10000 (78%)\n",
            "\n",
            "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.250380\n",
            "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.305423\n",
            "Test set(33): Average loss: 0.7435, Accuracy: 7879/10000 (79%)\n",
            "\n",
            "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.374033\n",
            "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.291534\n",
            "Test set(34): Average loss: 0.7929, Accuracy: 7753/10000 (78%)\n",
            "\n",
            "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.382580\n",
            "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.382125\n",
            "Test set(35): Average loss: 0.7963, Accuracy: 7695/10000 (77%)\n",
            "\n",
            "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.367801\n",
            "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.271379\n",
            "Test set(36): Average loss: 0.7216, Accuracy: 7861/10000 (79%)\n",
            "\n",
            "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.333942\n",
            "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.290068\n",
            "Test set(37): Average loss: 0.6782, Accuracy: 7998/10000 (80%)\n",
            "\n",
            "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.284552\n",
            "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.268207\n",
            "Test set(38): Average loss: 0.7898, Accuracy: 7870/10000 (79%)\n",
            "\n",
            "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.280131\n",
            "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.216311\n",
            "Test set(39): Average loss: 0.7270, Accuracy: 7969/10000 (80%)\n",
            "\n",
            "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.216989\n",
            "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.213786\n",
            "Test set(40): Average loss: 0.7390, Accuracy: 7854/10000 (79%)\n",
            "\n",
            "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.267448\n",
            "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.254663\n",
            "Test set(41): Average loss: 0.7115, Accuracy: 8063/10000 (81%)\n",
            "\n",
            "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.149201\n",
            "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.269891\n",
            "Test set(42): Average loss: 0.7461, Accuracy: 7990/10000 (80%)\n",
            "\n",
            "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.246510\n",
            "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.200183\n",
            "Test set(43): Average loss: 0.7812, Accuracy: 7919/10000 (79%)\n",
            "\n",
            "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.186589\n",
            "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.217735\n",
            "Test set(44): Average loss: 0.8968, Accuracy: 7712/10000 (77%)\n",
            "\n",
            "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.227525\n",
            "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.204238\n",
            "Test set(45): Average loss: 0.6527, Accuracy: 8172/10000 (82%)\n",
            "\n",
            "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.110213\n",
            "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.227139\n",
            "Test set(46): Average loss: 0.7250, Accuracy: 8056/10000 (81%)\n",
            "\n",
            "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.215391\n",
            "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.172519\n",
            "Test set(47): Average loss: 0.7269, Accuracy: 8084/10000 (81%)\n",
            "\n",
            "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.203532\n",
            "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.197658\n",
            "Test set(48): Average loss: 0.8683, Accuracy: 7863/10000 (79%)\n",
            "\n",
            "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.141688\n",
            "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.165987\n",
            "Test set(49): Average loss: 0.7374, Accuracy: 8173/10000 (82%)\n",
            "\n",
            "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.135652\n",
            "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.158899\n",
            "Test set(50): Average loss: 0.7251, Accuracy: 8170/10000 (82%)\n",
            "\n",
            "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.228308\n",
            "Train Epoch: 51 [25600/50000 (51%)]\tLoss: 0.203421\n",
            "Test set(51): Average loss: 0.7704, Accuracy: 8107/10000 (81%)\n",
            "\n",
            "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.211449\n",
            "Train Epoch: 52 [25600/50000 (51%)]\tLoss: 0.124368\n",
            "Test set(52): Average loss: 0.7270, Accuracy: 8176/10000 (82%)\n",
            "\n",
            "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.121906\n",
            "Train Epoch: 53 [25600/50000 (51%)]\tLoss: 0.128754\n",
            "Test set(53): Average loss: 0.7773, Accuracy: 8176/10000 (82%)\n",
            "\n",
            "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.135088\n",
            "Train Epoch: 54 [25600/50000 (51%)]\tLoss: 0.105979\n",
            "Test set(54): Average loss: 0.7602, Accuracy: 8128/10000 (81%)\n",
            "\n",
            "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.090531\n",
            "Train Epoch: 55 [25600/50000 (51%)]\tLoss: 0.121096\n",
            "Test set(55): Average loss: 0.7270, Accuracy: 8210/10000 (82%)\n",
            "\n",
            "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.097555\n",
            "Train Epoch: 56 [25600/50000 (51%)]\tLoss: 0.108195\n",
            "Test set(56): Average loss: 0.8103, Accuracy: 8078/10000 (81%)\n",
            "\n",
            "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.119954\n",
            "Train Epoch: 57 [25600/50000 (51%)]\tLoss: 0.135748\n",
            "Test set(57): Average loss: 0.7878, Accuracy: 8183/10000 (82%)\n",
            "\n",
            "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.119622\n",
            "Train Epoch: 58 [25600/50000 (51%)]\tLoss: 0.106447\n",
            "Test set(58): Average loss: 0.7426, Accuracy: 8258/10000 (83%)\n",
            "\n",
            "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.089173\n",
            "Train Epoch: 59 [25600/50000 (51%)]\tLoss: 0.118310\n",
            "Test set(59): Average loss: 0.9744, Accuracy: 7915/10000 (79%)\n",
            "\n",
            "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.122931\n",
            "Train Epoch: 60 [25600/50000 (51%)]\tLoss: 0.127935\n",
            "Test set(60): Average loss: 0.8178, Accuracy: 8148/10000 (81%)\n",
            "\n",
            "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.073905\n",
            "Train Epoch: 61 [25600/50000 (51%)]\tLoss: 0.113783\n",
            "Test set(61): Average loss: 0.7940, Accuracy: 8182/10000 (82%)\n",
            "\n",
            "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.102630\n",
            "Train Epoch: 62 [25600/50000 (51%)]\tLoss: 0.080897\n",
            "Test set(62): Average loss: 0.8948, Accuracy: 8081/10000 (81%)\n",
            "\n",
            "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.117315\n",
            "Train Epoch: 63 [25600/50000 (51%)]\tLoss: 0.071834\n",
            "Test set(63): Average loss: 0.8774, Accuracy: 8132/10000 (81%)\n",
            "\n",
            "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.036704\n",
            "Train Epoch: 64 [25600/50000 (51%)]\tLoss: 0.075499\n",
            "Test set(64): Average loss: 0.7998, Accuracy: 8240/10000 (82%)\n",
            "\n",
            "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.055276\n",
            "Train Epoch: 65 [25600/50000 (51%)]\tLoss: 0.121964\n",
            "Test set(65): Average loss: 0.7900, Accuracy: 8327/10000 (83%)\n",
            "\n",
            "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.078445\n",
            "Train Epoch: 66 [25600/50000 (51%)]\tLoss: 0.071226\n",
            "Test set(66): Average loss: 0.8216, Accuracy: 8303/10000 (83%)\n",
            "\n",
            "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.099013\n",
            "Train Epoch: 67 [25600/50000 (51%)]\tLoss: 0.063032\n",
            "Test set(67): Average loss: 0.8649, Accuracy: 8229/10000 (82%)\n",
            "\n",
            "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.126043\n",
            "Train Epoch: 68 [25600/50000 (51%)]\tLoss: 0.070858\n",
            "Test set(68): Average loss: 0.7951, Accuracy: 8317/10000 (83%)\n",
            "\n",
            "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.068461\n",
            "Train Epoch: 69 [25600/50000 (51%)]\tLoss: 0.089187\n",
            "Test set(69): Average loss: 0.8981, Accuracy: 8226/10000 (82%)\n",
            "\n",
            "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.142368\n",
            "Train Epoch: 70 [25600/50000 (51%)]\tLoss: 0.103370\n",
            "Test set(70): Average loss: 0.9074, Accuracy: 8168/10000 (82%)\n",
            "\n",
            "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.048507\n",
            "Train Epoch: 71 [25600/50000 (51%)]\tLoss: 0.038785\n",
            "Test set(71): Average loss: 0.8032, Accuracy: 8366/10000 (84%)\n",
            "\n",
            "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.068591\n",
            "Train Epoch: 72 [25600/50000 (51%)]\tLoss: 0.057486\n",
            "Test set(72): Average loss: 0.9637, Accuracy: 8193/10000 (82%)\n",
            "\n",
            "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.065926\n",
            "Train Epoch: 73 [25600/50000 (51%)]\tLoss: 0.035189\n",
            "Test set(73): Average loss: 1.0180, Accuracy: 8018/10000 (80%)\n",
            "\n",
            "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.088184\n",
            "Train Epoch: 74 [25600/50000 (51%)]\tLoss: 0.035725\n",
            "Test set(74): Average loss: 0.8419, Accuracy: 8318/10000 (83%)\n",
            "\n",
            "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.026305\n",
            "Train Epoch: 75 [25600/50000 (51%)]\tLoss: 0.037291\n",
            "Test set(75): Average loss: 0.9030, Accuracy: 8285/10000 (83%)\n",
            "\n",
            "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.044249\n",
            "Train Epoch: 76 [25600/50000 (51%)]\tLoss: 0.053621\n",
            "Test set(76): Average loss: 0.9551, Accuracy: 8219/10000 (82%)\n",
            "\n",
            "Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.093577\n",
            "Train Epoch: 77 [25600/50000 (51%)]\tLoss: 0.035471\n",
            "Test set(77): Average loss: 0.9856, Accuracy: 8217/10000 (82%)\n",
            "\n",
            "Train Epoch: 78 [0/50000 (0%)]\tLoss: 0.046047\n",
            "Train Epoch: 78 [25600/50000 (51%)]\tLoss: 0.057892\n",
            "Test set(78): Average loss: 0.8267, Accuracy: 8405/10000 (84%)\n",
            "\n",
            "Train Epoch: 79 [0/50000 (0%)]\tLoss: 0.028369\n",
            "Train Epoch: 79 [25600/50000 (51%)]\tLoss: 0.060615\n",
            "Test set(79): Average loss: 0.9179, Accuracy: 8275/10000 (83%)\n",
            "\n",
            "Train Epoch: 80 [0/50000 (0%)]\tLoss: 0.035673\n",
            "Train Epoch: 80 [25600/50000 (51%)]\tLoss: 0.033070\n",
            "Test set(80): Average loss: 0.9900, Accuracy: 8218/10000 (82%)\n",
            "\n",
            "Train Epoch: 81 [0/50000 (0%)]\tLoss: 0.050637\n",
            "Train Epoch: 81 [25600/50000 (51%)]\tLoss: 0.053106\n",
            "Test set(81): Average loss: 0.9689, Accuracy: 8230/10000 (82%)\n",
            "\n",
            "Train Epoch: 82 [0/50000 (0%)]\tLoss: 0.066360\n",
            "Train Epoch: 82 [25600/50000 (51%)]\tLoss: 0.065412\n",
            "Test set(82): Average loss: 0.9897, Accuracy: 8190/10000 (82%)\n",
            "\n",
            "Train Epoch: 83 [0/50000 (0%)]\tLoss: 0.041263\n",
            "Train Epoch: 83 [25600/50000 (51%)]\tLoss: 0.049198\n",
            "Test set(83): Average loss: 0.9057, Accuracy: 8346/10000 (83%)\n",
            "\n",
            "Train Epoch: 84 [0/50000 (0%)]\tLoss: 0.039979\n",
            "Train Epoch: 84 [25600/50000 (51%)]\tLoss: 0.024532\n",
            "Test set(84): Average loss: 0.9908, Accuracy: 8230/10000 (82%)\n",
            "\n",
            "Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.043582\n",
            "Train Epoch: 85 [25600/50000 (51%)]\tLoss: 0.062664\n",
            "Test set(85): Average loss: 0.8602, Accuracy: 8406/10000 (84%)\n",
            "\n",
            "Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.034372\n",
            "Train Epoch: 86 [25600/50000 (51%)]\tLoss: 0.021096\n",
            "Test set(86): Average loss: 0.9980, Accuracy: 8255/10000 (83%)\n",
            "\n",
            "Train Epoch: 87 [0/50000 (0%)]\tLoss: 0.023342\n",
            "Train Epoch: 87 [25600/50000 (51%)]\tLoss: 0.044142\n",
            "Test set(87): Average loss: 0.8563, Accuracy: 8448/10000 (84%)\n",
            "\n",
            "Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.023805\n",
            "Train Epoch: 88 [25600/50000 (51%)]\tLoss: 0.032299\n",
            "Test set(88): Average loss: 0.8962, Accuracy: 8357/10000 (84%)\n",
            "\n",
            "Train Epoch: 89 [0/50000 (0%)]\tLoss: 0.043388\n",
            "Train Epoch: 89 [25600/50000 (51%)]\tLoss: 0.034681\n",
            "Test set(89): Average loss: 0.8713, Accuracy: 8407/10000 (84%)\n",
            "\n",
            "Train Epoch: 90 [0/50000 (0%)]\tLoss: 0.030660\n",
            "Train Epoch: 90 [25600/50000 (51%)]\tLoss: 0.028194\n",
            "Test set(90): Average loss: 0.9726, Accuracy: 8317/10000 (83%)\n",
            "\n",
            "Train Epoch: 91 [0/50000 (0%)]\tLoss: 0.028331\n",
            "Train Epoch: 91 [25600/50000 (51%)]\tLoss: 0.026440\n",
            "Test set(91): Average loss: 0.8418, Accuracy: 8453/10000 (85%)\n",
            "\n",
            "Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.018058\n",
            "Train Epoch: 92 [25600/50000 (51%)]\tLoss: 0.026741\n",
            "Test set(92): Average loss: 0.9237, Accuracy: 8374/10000 (84%)\n",
            "\n",
            "Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.019047\n",
            "Train Epoch: 93 [25600/50000 (51%)]\tLoss: 0.013772\n",
            "Test set(93): Average loss: 0.8859, Accuracy: 8423/10000 (84%)\n",
            "\n",
            "Train Epoch: 94 [0/50000 (0%)]\tLoss: 0.007680\n",
            "Train Epoch: 94 [25600/50000 (51%)]\tLoss: 0.010935\n",
            "Test set(94): Average loss: 0.9711, Accuracy: 8333/10000 (83%)\n",
            "\n",
            "Train Epoch: 95 [0/50000 (0%)]\tLoss: 0.063488\n",
            "Train Epoch: 95 [25600/50000 (51%)]\tLoss: 0.009553\n",
            "Test set(95): Average loss: 0.9512, Accuracy: 8345/10000 (83%)\n",
            "\n",
            "Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.032319\n",
            "Train Epoch: 96 [25600/50000 (51%)]\tLoss: 0.038403\n",
            "Test set(96): Average loss: 0.9708, Accuracy: 8360/10000 (84%)\n",
            "\n",
            "Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.073884\n",
            "Train Epoch: 97 [25600/50000 (51%)]\tLoss: 0.027278\n",
            "Test set(97): Average loss: 0.9015, Accuracy: 8409/10000 (84%)\n",
            "\n",
            "Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.028692\n",
            "Train Epoch: 98 [25600/50000 (51%)]\tLoss: 0.013389\n",
            "Test set(98): Average loss: 1.0418, Accuracy: 8262/10000 (83%)\n",
            "\n",
            "Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.034397\n",
            "Train Epoch: 99 [25600/50000 (51%)]\tLoss: 0.022738\n",
            "Test set(99): Average loss: 0.9753, Accuracy: 8356/10000 (84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq3rhItXRZrJ",
        "outputId": "8e8c1df4-a754-420d-b3f8-7f7c1f1c5f6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(84.5300)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}